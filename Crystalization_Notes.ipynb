{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crystalization Notes\n",
    "\n",
    "## 2017-10-09\n",
    "Should have started this weeks ago.  Anyway, the idea is that we can use a variant of [this PPT by Cho](http://web.ecs.baylor.edu/faculty/cho/Cho-Entropy.pdf) to subgraphs of minimal energy.  \n",
    "\n",
    "The ultimate goal is to take a patients CUI set and find the maximally fitting set of conditions for them.  The conditions should initially be informed by the \"Conditions\" listed with the CT.gov dataset, but at some point we'll let users construct their own.\n",
    "\n",
    "\n",
    "### Recipe Reconstruction\n",
    "The [Yummly Data](https://www.kaggle.com/c/whats-cooking) seems a nice analogy.  They provide a three-tiered data set that includes \"Cuisine > Recipe > Ingredients\".  [This guy](https://github.com/Btibert3/kaggle-yummly) tried it in Neo4j. The Recipe is just an idea. The intent of the competition was to be able to predict the cuisine given just the ingredients.  However, in our analogy I want to find the \"maximally fitting\" recipe for a given set of ingredients.  We don't have labels for this, so I don't have the success metric yet.\n",
    "\n",
    "I took a set of about 124 recipes to run the minimal energy routine on.  Unfortunately, I messed up the code and I mistook it for not doing the minimization.  Specifically, I we returning the size of `cupboard` which is just the set of ingredient ids instead of returning the output of `minEnergy`.  To solve the problem I didn't have, I created the `knockout` routine, which removes a few ingredients from each recipe before it gets sent in for minimization.\n",
    "\n",
    "The `knockout` routine may or may not be causing very small crystals.  I'm running some metrics on that now.  However, `knockout` isn't necessary right now since the error never really existed.\n",
    "\n",
    "I think one of the issues it that the crystals are small because the data set is not very connected. In the 124 set, we don't get much coverage of any one cuisine, and though I'm not sure how to test it, I'm thinking highly specific ingredients are experiencing very low degrees.\n",
    "\n",
    "I still feel confident the method will be informative, but it's not being as cooperative as I'd like.\n",
    "\n",
    "Today, I think I'm going to try to extract all \"Italian\" recipes or something like that.  Actually, I should probably pull the whole thing into Postgres so I can sub-set as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DROP TABLE IF EXISTS r.yummly;\n",
    "CREATE TABLE r.yummly\n",
    "(cuisine text\n",
    ", recipe int\n",
    ", ingredient text\n",
    ");\n",
    "\\copy r.yummly from yummly.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT n_cuisines\n",
    ", count(*)\n",
    "FROM (\n",
    "    SELECT ingredient\n",
    "    , count(distinct(cuisine)) AS n_cuisines\n",
    "    FROM r.yummly\n",
    "    GROUP BY 1\n",
    ") AS a\n",
    "GROUP BY n_cuisines\n",
    "ORDER BY 1,2;\n",
    "\n",
    "\n",
    " n_cuisines | count\n",
    "------------+-------\n",
    "          1 |  2597\n",
    "          2 |  1009\n",
    "          3 |   588\n",
    "          4 |   460\n",
    "          5 |   323\n",
    "          6 |   257\n",
    "          7 |   220\n",
    "          8 |   177\n",
    "          9 |   159\n",
    "         10 |   127\n",
    "         11 |   110\n",
    "         12 |   100\n",
    "         13 |    81\n",
    "         14 |    76\n",
    "         15 |    72\n",
    "         16 |    61\n",
    "         17 |    65\n",
    "         18 |    57\n",
    "         19 |    68\n",
    "         20 |   107\n",
    "(20 rows)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 11 October, 2017\n",
    "\n",
    "I realized yesterday we are running into the super node problem, just like in the UMLS data, so that is VERY GOOD.  However, I needed to build an ECDF function into NumSuch to handle this.  That took pretty much all day.\n",
    "\n",
    "This means I should install a method in GraphUtils to return the degree of each vertex. \n",
    "\n",
    "...okay done\n",
    "\n",
    "Next, it seems I should create a sub-graph of the lower degree nodes and see how that works.\n",
    "\n",
    "4:30 AM. Still working on that. Looks like I'm beginning to build my own Graph Processing System, which I do NOT want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
